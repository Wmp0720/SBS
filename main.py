
import os
import sys
import argparse
from evaluation import load_rules, create_reflection_prompt, test
from processor_threaded import process_data_multithread
# from processor import process_data
from check_consistency import compute_consistency, add_consistency_flag_columns
from utils.tee import Tee
from merge_outputs import merge_thread_outputs
import pandas as pd
from check_consistency import compute_consistency, add_consistency_flag_columns, _normalize_columns


def format_df_to_markdown(df: pd.DataFrame) -> str:
    """è¾…åŠ©å‡½æ•°ï¼šå°†DataFrameæ ¼å¼åŒ–ä¸ºMarkdownè¡¨æ ¼å­—ç¬¦ä¸²"""
    return df.to_markdown(index=False)


if __name__ == "__main__":
    # ===============================
    # å‘½ä»¤è¡Œå‚æ•°è§£æ
    parser = argparse.ArgumentParser(description="è‡ªåŠ¨åŒ–è¯„æµ‹ç³»ç»Ÿ")
    parser.add_argument("--model", default="o3",
                       help="ä½¿ç”¨çš„æ¨¡å‹åç§°")
    parser.add_argument("--dataset", default="test4.xlsx",
                       help="æ•°æ®é›†æ–‡ä»¶å")
    parser.add_argument("--golden", default="config/golden_dataset.xlsx",
                       help="ç²¾æ ‡æ•°æ®é›†è·¯å¾„")
    parser.add_argument("--threads", type=int, default=5,
                       help="å¹¶å‘çº¿ç¨‹æ•°")
    parser.add_argument("--version", default="test4",
                       help="ç»“æœç›®å½•ç‰ˆæœ¬æ ‡è®°")
    parser.add_argument("--verbose", action="store_true",
                       help="å¯ç”¨è¯¦ç»†æ—¥å¿—è¾“å‡º")
    parser.add_argument("--show-prompts", action="store_true",
                       help="æ˜¾ç¤ºå®Œæ•´çš„promptå†…å®¹")
    args = parser.parse_args()

    # ===============================
    # æ€»å¼€å…³ï¼Œæ§åˆ¶æ˜¯å¦æ‰“å°è¯¦ç»†æ—¥å¿—
    VERBOSE_MODE = args.verbose  # è®¾ç½®ä¸º False æ¥å…³é—­è¯¦ç»†Promptæ‰“å°ï¼Œéœ€è¦è°ƒè¯•æ—¶æ”¹ä¸º True
    SHOW_PROMPTS = args.show_prompts  # æ§åˆ¶æ˜¯å¦æ˜¾ç¤ºå®Œæ•´çš„promptå†…å®¹
    # ===============================
    model_name = args.model  # å¯é€‰ï¼šgpt_4o/deepseek-r1/è±†åŒ…1.5_pro/o3/gemini-2.5-pro/Doubao-1.6-agent-proç­‰
    dataset = args.dataset  # æ•°æ®é›†æ–‡ä»¶å
    golden_dataset_path = args.golden
    thread_num = args.threads  # å¹¶å‘çº¿ç¨‹æ•°
    version = args.version  # ç»“æœç›®å½•ç‰ˆæœ¬æ ‡è®°
    # ==============================

    # è¾“å‡ºæ–‡ä»¶çš„è·¯å¾„è§„åˆ’
    current_dir = os.path.dirname(os.path.abspath(__file__))
    file_path = os.path.join(current_dir, "Datesets", dataset)
    output_dir = os.path.join(current_dir, "Results", version,
                              os.path.basename(file_path).replace(".xlsx", f"_{model_name}"))
    output_dir_mutithread = os.path.join(output_dir, "multithread")
    final_output_file = os.path.join(output_dir,
                                     f"{os.path.basename(file_path).replace('.xlsx', '')}_{model_name}Eval.xlsx")

    # ã€è¯´æ˜ã€‘ç¡®ä¿æˆ‘ä»¬å¯¼å…¥äº†æ­£ç¡®çš„å‡½æ•°
    # from check_consistency import compute_consistency, add_consistency_flag_columns

    rules = load_rules()

    # =================== åæ€å­¦ä¹ é˜¶æ®µ ===================
    print("--- é˜¶æ®µé›¶ï¼šLLMåæ€å­¦ä¹ é˜¶æ®µ ---")
    try:
        golden_df = pd.read_excel(os.path.join(current_dir, golden_dataset_path))
        key_columns = [
            "prompt_content", "å°Vcompletions_content", "ç«å“completions_content",
            "æ ‡æ³¨å‘˜_å°vä¸»è¦é—®é¢˜", "æ ‡æ³¨å‘˜_ç«å“ä¸»è¦é—®é¢˜", "æ ‡æ³¨å‘˜_å°vç«å“å¯¹æ¯”",
            "LLMs_è‡ªç ”ä¸»è¦é—®é¢˜", "LLMs_ç«å“ä¸»è¦é—®é¢˜", "LLMs_è‡ªç ”ç«å“å¯¹æ¯”"
        ]
        key_columns_exist = [col for col in key_columns if col in golden_df.columns]
        golden_samples_df = golden_df[key_columns_exist].head(9)
        golden_samples_str = format_df_to_markdown(golden_samples_df)
        reflection_prompt = create_reflection_prompt(golden_samples_str, rules)

        print("æ­£åœ¨è¯·æ±‚LLMå­¦ä¹ ç²¾æ ‡æ•°æ®å¹¶ç”Ÿæˆè¯„æµ‹æŒ‡å—...")
        learned_guidelines = test(reflection_prompt, model=model_name, verbose=VERBOSE_MODE, show_prompts=SHOW_PROMPTS)
        print("LLMå­¦ä¹ å®Œæˆï¼Œç”Ÿæˆçš„è¯„æµ‹æŒ‡å—å¦‚ä¸‹ï¼š\n", learned_guidelines)

        rules['learned_guidelines'] = learned_guidelines
    except FileNotFoundError:
        print(f"[è­¦å‘Š] æœªæ‰¾åˆ°ç²¾æ ‡æ•°æ®é›†: {golden_dataset_path}ã€‚å°†è·³è¿‡å­¦ä¹ é˜¶æ®µã€‚")
        rules['learned_guidelines'] = "æ— "
    except Exception as e:
        print(f"[é”™è¯¯] LLMå­¦ä¹ é˜¶æ®µå¤±è´¥: {e}ã€‚å°†è·³è¿‡å­¦ä¹ é˜¶æ®µã€‚")
        rules['learned_guidelines'] = "æ— "
    print("------------------------------------\n")

    # =================== è¯„æµ‹æ‰§è¡Œä¸åˆå¹¶ ===================
    print(f"--- é˜¶æ®µä¸€ï¼šå¼€å§‹å¯¹ {dataset} è¿›è¡Œå¤šçº¿ç¨‹è¯„æµ‹ ---")
    process_data_multithread(
        file_path,
        output_dir_mutithread,
        model_name=model_name,
        rules=rules,
        thread_num=thread_num,
        verbose=VERBOSE_MODE,
        show_prompts=SHOW_PROMPTS
    )
    print("\n--- é˜¶æ®µäºŒï¼šåˆå¹¶å¤šçº¿ç¨‹ç»“æœæ–‡ä»¶ ---")
    merge_thread_outputs(output_dir_mutithread, model_name, final_output_file)
    print(f"âœ… å¤šçº¿ç¨‹ç»“æœå·²åˆå¹¶è‡³: {final_output_file}")

    # =================== åå¤„ç†ï¼šæ·»åŠ æ ‡è®°åˆ— ===================
    print("\n--- é˜¶æ®µä¸‰ï¼šä¸ºæœ€ç»ˆç»“æœæ–‡ä»¶æ·»åŠ 'äººæœºä¸€è‡´'æ ‡è®°åˆ— ---")
    try:
        print(f"æ­£åœ¨è¯»å–åˆå¹¶åçš„æ–‡ä»¶: {final_output_file}")
        final_df = pd.read_excel(final_output_file)
        print(f"è¯»å–æˆåŠŸï¼ŒåŸå§‹åˆ—æ•°: {len(final_df.columns)}")

        final_df = _normalize_columns(final_df)
        print(f"å½’ä¸€åŒ–ååˆ—: {final_df.columns.to_list()}")

        # è°ƒç”¨å‡½æ•°æ·»åŠ æ ‡è®°åˆ—
        final_df_with_flags = add_consistency_flag_columns(final_df)
        print(f"æ ‡è®°åˆ—æ·»åŠ å®Œæˆï¼Œå½“å‰åˆ—æ•°: {len(final_df_with_flags.columns)}")

        # å°†å¸¦æœ‰æ–°åˆ—çš„DataFrameå†™å›ï¼Œè¦†ç›–åŸæ–‡ä»¶
        print(f"æ­£åœ¨å°†æ›´æ–°åçš„æ•°æ®å†™å›æ–‡ä»¶ï¼Œè¿™ä¼šè¦†ç›–åŸæœ‰å†…å®¹...")
        final_df_with_flags.to_excel(final_output_file, index=False)
        print(f"âœ… ä¸‰åˆ—æ ‡è®°åˆ—å·²æˆåŠŸæ·»åŠ å¹¶ä¿å­˜å›: {final_output_file}")
    except FileNotFoundError:
        print(f"[é”™è¯¯] æœªæ‰¾åˆ°æœ€ç»ˆç»“æœæ–‡ä»¶: {final_output_file}ï¼Œè·³è¿‡æ·»åŠ æ ‡è®°åˆ—ã€‚")
    except Exception as e:
        print(f"[ä¸¥é‡é”™è¯¯] æ·»åŠ æ ‡è®°åˆ—æ—¶å‘ç”Ÿå¤±è´¥: {e}")
        # åœ¨è¿™é‡Œå¯ä»¥åŠ å…¥æ›´è¯¦ç»†çš„é”™è¯¯è¿½æº¯
        import traceback

        traceback.print_exc()

    # =================== æœ€ç»ˆåˆ†æ ===================
    print("\n--- é˜¶æ®µå››ï¼šåœ¨å·²åŒ…å«æ ‡è®°åˆ—çš„æ–‡ä»¶ä¸Šæ‰§è¡Œä¸€è‡´æ€§ç»Ÿè®¡ ---")
    # ã€è¯´æ˜ã€‘compute_consistency å‡½æ•°è®¾è®¡ä¸ºåœ¨ç°æœ‰æ–‡ä»¶ä¸Šè¿½åŠ æˆ–æ›¿æ¢sheetï¼Œ
    # å®ƒä¸ä¼šä¿®æ”¹æ–‡ä»¶ä¸­çš„ç¬¬ä¸€ä¸ªsheetï¼ˆå³æˆ‘ä»¬åˆšåˆšå†™å…¥çš„ä¸»æ•°æ®ï¼‰ã€‚
    try:
        compute_consistency(file_path=final_output_file, model_name=model_name)
        print(f"\nğŸ‰ğŸ‰ğŸ‰ æ‰€æœ‰æµç¨‹æ‰§è¡Œå®Œæ¯•ï¼æœ€ç»ˆçš„å®Œæ•´æŠ¥å‘Šå·²ç”Ÿæˆåœ¨: {final_output_file}")
    except Exception as e:
        print(f"[ä¸¥é‡é”™è¯¯] æ‰§è¡Œæœ€ç»ˆä¸€è‡´æ€§åˆ†ææ—¶å¤±è´¥: {e}")
        import traceback

        traceback.print_exc()